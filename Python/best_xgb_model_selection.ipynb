{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1236add",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.metrics as skm\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import sys\n",
    "import time\n",
    "import matplotlib\n",
    "import xgboost as xgb\n",
    "import seaborn as s\n",
    "from lib_submision import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598cbbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = CEventsTable()\n",
    "t.appendFromCsv(\"ivan_ntuples/tH.csv\",1,\"tH\")\n",
    "t.appendFromCsv(\"ivan_ntuples/ttb.csv\",0,\"ttb\")\n",
    "t.appendFromCsv(\"ivan_ntuples/ttc.csv\",0,\"ttc\")\n",
    "t.appendFromCsv(\"ivan_ntuples/ttL.csv\",0,\"ttL\")\n",
    "t.appendFromCsv(\"nazim_ntuples/ttH.csv\",0,\"ttH\")\n",
    "t.appendFromCsv(\"nazim_ntuples/ttZ.csv\",0,\"ttZ\")\n",
    "t.appendFromCsv(\"ivan_ntuples/ttW.csv\",0,\"ttW\")\n",
    "t.appendFromCsv(\"ivan_ntuples/tZq.csv\",0,\"tZq\")\n",
    "t.appendFromCsv(\"ivan_ntuples/tWZ.csv\",0,\"tWZ\")\n",
    "t.appendFromCsv(\"ivan_ntuples/tW.csv\",0,\"single_tW\")\n",
    "t.appendFromCsv(\"ivan_ntuples/single_t1.csv\",0,\"single_tt\")\n",
    "t.appendFromCsv(\"ivan_ntuples/single_t2.csv\",0,\"single_tt\")\n",
    "t.appendFromCsv(\"ivan_ntuples/single_ts.csv\",0,\"single_ts\")\n",
    "t.appendFromCsv(\"nazim_ntuples/WZ.csv\",0,\"WZ\")\n",
    "t.appendFromCsv(\"nazim_ntuples/VV1.csv\",0,\"VV\")\n",
    "t.appendFromCsv(\"nazim_ntuples/VV2.csv\",0,\"VV\")\n",
    "t.appendFromCsv(\"ivan_ntuples/data.csv\",0,\"nonp\")\n",
    "\n",
    "t.subSample('ttH', 0.1)\n",
    "\n",
    "\n",
    "print('Before preselection:')\n",
    "t.printTypesNumbers()\n",
    "t.applyPreselection()\n",
    "print('After preselection:')\n",
    "t.printTypesNumbers()\n",
    "print('With weights:')\n",
    "t.calculateWeights()\n",
    "t.printTypesNumbers()\n",
    "\n",
    "\n",
    "    \n",
    "mld = CSampledDatasetExpEvents(t.table, (20000,100000),(10000,100000))\n",
    "#mld = CSampledDatasetAcc(t.table, (20000,100000), (10000,100000))\n",
    "mld.printInfo()\n",
    "\n",
    "\n",
    "X_train = mld.X_train\n",
    "y_train = mld.y_train\n",
    "types_train = mld.types_train\n",
    "weights_train = mld.weights_train\n",
    "\n",
    "X_test = mld.X_test\n",
    "y_test = mld.y_test\n",
    "types_test = mld.types_test\n",
    "weights_test = mld.weights_test\n",
    "\n",
    "\n",
    "X_val = mld.X_val\n",
    "y_val = mld.y_val\n",
    "types_val = mld.types_val\n",
    "weights_val = mld.weights_val\n",
    "\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "dval = xgb.DMatrix(X_val, label=y_val)\n",
    "\n",
    "\n",
    "\n",
    "AucCalc = CEvaluationAUC()\n",
    "SigCalc = CEvaluationSignificance()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb88ea49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prvni beh - optimalizace gbtree, depth, scale_pos_weight, lambda, alpha, gamma\n",
    "df1 = pd.read_csv('tpe_sampler/initial_parameters/expected_events/perfs.csv')\n",
    "df1['df_id'] = 1\n",
    "\n",
    "# dalsi beh initial parameters - optimalizace lambda, alpha, gamma, min_child_weight, colsample_bytree \n",
    "df2 = pd.read_csv('tpe_sampler/perfs.csv')\n",
    "df2['df_id'] = 2\n",
    "\n",
    "\n",
    "# nsga algoritmus (optimalizace auc) - optimalizace lambda, alpha, gamma, min_child_weight \n",
    "df3 = pd.DataFrame()\n",
    "for i in range(5):\n",
    "    _df = pd.read_csv('nsga/df' + str(i) )\n",
    "    df3 = pd.concat([df3, _df])\n",
    "df3['df_id'] = 3\n",
    "\n",
    "    \n",
    "# nsga algoritmus (optimalizace significance) - optimalizace lambda, alpha, gamma, min_child_weight \n",
    "df4 = pd.DataFrame()\n",
    "for i in range(5):\n",
    "    _df = pd.read_csv('nsga_sig/df' + str(i) )\n",
    "    df4 = pd.concat([df4, _df])\n",
    "df4['df_id'] = 4\n",
    "    \n",
    "# tpe (optimalizace sig) - lambda, alpha, gamma, min_child_weight (vetsi rozsahy) \n",
    "df5 = pd.DataFrame()\n",
    "for i in range(2):\n",
    "    _df = pd.read_csv('tpe_sampler_sig/df' + str(i) )\n",
    "    df5 = pd.concat([df5, _df])\n",
    "df5['df_id'] = 5    \n",
    "    \n",
    "# tpe (optimalizace sig) - lambda, alpha, gamma, min_child_weight, colsample_bytree \n",
    "df6 = pd.DataFrame()\n",
    "for i in range(4):\n",
    "    _df = pd.read_csv('tpe_sampler_sig2/df' + str(i) )\n",
    "    df6 = pd.concat([df6, _df])\n",
    "df6['df_id'] = 6\n",
    "    \n",
    "nsga = pd.concat([df3,df4])\n",
    "    \n",
    "dfa = pd.concat([df2,df3,df4,df5,df6])\n",
    "c = dfa.pop('df_id')\n",
    "dfa.insert(0, 'df_id', c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa046953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Getting best models from optuna analysis and saving them\n",
    "\n",
    "models = []\n",
    "\n",
    "for i in range(20):\n",
    "    row = dfa.iloc[i,:]\n",
    "    colsample_bytree = row['colsample_bytree']\n",
    "\n",
    "    if row['df_id'] == 5:\n",
    "        colsample_bytree = 0.6    \n",
    "        \n",
    "    best_epoch_t = row['best_epoch']\n",
    "\n",
    "    while 1:\n",
    "        (model, sig, auc, best_epoch) = evaluate_model(row['lambda'], row['alpha'], row['gamma'],\n",
    "                       row['min_child_weight'], colsample_bytree)\n",
    "        \n",
    "        print(best_epoch, best_epoch_t)\n",
    "        if best_epoch_t == best_epoch:\n",
    "            break\n",
    "        else:\n",
    "            print('results dont match, running again\\n')\n",
    "    \n",
    "    models.append([model,sig,auc])\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "for i in range(len(models)):\n",
    "    model = models[i][0]\n",
    "    \n",
    "    joblib.dump(model, \"nn_models/sig_opt/m\" + str(i))\n",
    "    model = joblib.load(\"nn_models/sig_opt/m\" + str(i))\n",
    "    \n",
    "    preds = model.predict(X_test)\n",
    "    auc = AucCalc.evaluate(preds, y_test)\n",
    "    significance, thr, sig, bg = SigCalc.evaluate(preds, y_test, weights_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a207a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "\n",
    "for i in range(20):\n",
    "    row = dfa.iloc[i,:]\n",
    "    colsample_bytree = row['colsample_bytree']\n",
    "\n",
    "    if row['df_id'] == 5:\n",
    "        colsample_bytree = 0.6    \n",
    "        \n",
    "    best_epoch_t = row['best_epoch']\n",
    "\n",
    "    while 1:\n",
    "        (model, sig, auc, best_epoch) = evaluate_model(row['lambda'], row['alpha'], row['gamma'],\n",
    "                       row['min_child_weight'], colsample_bytree)\n",
    "        \n",
    "        print(best_epoch, best_epoch_t)\n",
    "        if best_epoch_t == best_epoch:\n",
    "            break\n",
    "        else:\n",
    "            print('results dont match, running again\\n')\n",
    "    \n",
    "    models.append([model,sig,auc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f991bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_sigopt = []\n",
    "models_aucopt = []\n",
    "\n",
    "for i in range(20):\n",
    "    model = joblib.load(\"xgb_models/auc_opt/m\" + str(i))\n",
    "    models_aucopt.append(model)\n",
    "    \n",
    "    model = joblib.load(\"xgb_models/sig_opt2/m\" + str(i))\n",
    "    models_sigopt.append(model)\n",
    "    \n",
    "not_needed = CSampledDatasetExpEvents(t.table, (20000,100000))\n",
    "not_needed.printInfo()\n",
    "no_train = not_needed.X_test\n",
    "\n",
    "no_train['y'] = not_needed.y_test\n",
    "no_train['type'] = not_needed.types_test\n",
    "no_train['weight'] = not_needed.weights_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722ce988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting aucs and significance boxplots\n",
    "\n",
    "n_tests=10\n",
    "\n",
    "for i in range(n_tests):\n",
    "    samples = CSampledDatasetExpEvents(no_train, (20000,100000), rs = i)\n",
    "    X_samples = samples.X_train\n",
    "    y_samples = samples.y_train\n",
    "    weights_samples = samples.weights_train\n",
    "    \n",
    "    for m in range(len(models_aucopt)):\n",
    "        mod_auc = models_aucopt[m]\n",
    "\n",
    "        preds = mod_auc.predict(X_samples)\n",
    "        auc = AucCalc.evaluate(preds, y_samples, print_score=False)\n",
    "        significance, thr, sig, bg = SigCalc.evaluate(preds, y_samples, weights_samples, print_score=False)\n",
    "        \n",
    "        aucs.loc[i, \"auc_opt\" + str(m)] = auc\n",
    "        sigs.loc[i, \"auc_opt\" + str(m)] = significance\n",
    "        n_signals.loc[i, \"auc_opt\" + str(m)] = sig\n",
    "        \n",
    "        mod_sig = models_sigopt[m]\n",
    "        \n",
    "        preds = mod_sig.predict(X_samples)\n",
    "        auc = AucCalc.evaluate(preds, y_samples, print_score=False)\n",
    "        significance, thr, sig, bg = SigCalc.evaluate(preds, y_samples, weights_samples, print_score=False)\n",
    "        \n",
    "        aucs.loc[i, \"sig_opt\" + str(m)] = auc\n",
    "        sigs.loc[i, \"sig_opt\" + str(m)] = significance\n",
    "        n_signals.loc[i, \"sig_opt\" + str(m)] = sig\n",
    "    \n",
    "    display(aucs.head(10))\n",
    "    display(sigs.head(10))\n",
    "    display(n_signals.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d3cf48",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = sigs.iloc[:, 0:10]\n",
    "\n",
    "\n",
    "matplotlib.rcParams.update({'font.size': 12,'font.weight':'normal'})\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.grid(True)\n",
    "\n",
    "\n",
    "boxprops = dict(linestyle='-', linewidth=1.5, color='k')\n",
    "whiskerprops = dict(linestyle='-', linewidth=1.5, color='k')\n",
    "capprops = dict(linestyle='-', linewidth=1.5, color='k')\n",
    "\n",
    "plt.xlabel(\"Model\")\n",
    "plt.ylabel(\"AUC\")\n",
    "\n",
    "plt.boxplot(p, labels=range(10), \n",
    "            boxprops=boxprops, whiskerprops=whiskerprops, capprops=capprops)\n",
    "plt.savefig('diplomka_obrazky/models_sig_boxplots.png',dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51514c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# showing multiple significance plots in on graph\n",
    "\n",
    "for i in range(0,6):    \n",
    "    samples = CSampledDatasetExpEvents(no_train, (20000,100000), rs = i)\n",
    "    \n",
    "    X_samples = samples.X_train\n",
    "    y_samples = samples.y_train\n",
    "    weights_samples = samples.weights_train\n",
    "\n",
    "\n",
    "    model = models_sigopt[1]\n",
    "\n",
    "    preds = model.predict(X_samples)\n",
    "    auc = AucCalc.evaluate(preds, y_samples, print_score=True, show_graph=True)\n",
    "    significance, thr, sig, bg = SigCalc.evaluate(preds, y_samples, weights_samples, \n",
    "                                                  print_score=True, show_graph=False, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d63e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting feature importances of different models\n",
    "\n",
    "df=pd.DataFrame(columns = ['njets_CBT5', 'leptons_charge', 'nbjets', 'chi2_min_tophad_m_ttAll', 'fwdjets_pt', \n",
    "                           'nnonbjets', 'sphericity', 'nonbjets_pt', 'nfwdjets', 'chi2_min_DeltaEta_tH', 'chi2_min_bbnonbjet_m', \n",
    "                           'chi2_min_higgs_m', 'chi2_min_Whad_m_ttAll', 'inv3jets', 'nonbjets_eta','rapgap_top_fwdjet', 'chi2_min_toplep_pt', \n",
    "                           'aplanarity', 'chi2_min_Imvmass_tH', \n",
    "                           'tagnonb_topb_m','tagnonb_eta','rapgap_maxptjet','chi2_min_deltaRq1q2','foxWolfram_2_momentum'])\n",
    "\n",
    "for i in range(20):\n",
    "    l = pd.DataFrame(models_sigopt[i].model.get_score( importance_type='gain'), index= [i])\n",
    "    df = pd.concat([df,l])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "matplotlib.rcParams.update({'font.size': 13,'font.weight':'normal'})\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.grid(True)\n",
    "\n",
    "\n",
    "boxprops = dict(linestyle='-', linewidth=1.5, color='k')\n",
    "whiskerprops = dict(linestyle='-', linewidth=1.5, color='k')\n",
    "capprops = dict(linestyle='-', linewidth=1.5, color='k')\n",
    "\n",
    "\n",
    "plt.xlabel(\"Importance rank\")\n",
    "plt.ylabel(\"Average gain\")\n",
    "\n",
    "plt.boxplot(df, labels=range(24), \n",
    "            boxprops=boxprops, whiskerprops=whiskerprops, capprops=capprops)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f55c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training of different models on a subset of features\n",
    "\n",
    "def evaluate_model(lambdaa, alpha, gamma, min_child_weight, colsample_bytree):\n",
    "    booster = 'gbtree'\n",
    "    max_depth = 5\n",
    "    scale_pos_weight = 1.0\n",
    "\n",
    "\n",
    "    model = XGBWrapper()\n",
    "    model.train(dtrain, 10000, max_depth, 0.1, dval, \n",
    "                scale_pos_weight = scale_pos_weight, lambdaa = lambdaa,\n",
    "                alpha = alpha, gamma = gamma, booster = booster, \n",
    "                min_child_weight = min_child_weight, colsample_bytree = colsample_bytree)\n",
    "\n",
    "    auc_test = model.best_performance\n",
    "    auc_train = model.best_performance_train\n",
    "    best_epoch = model.best_epoch\n",
    "    n_epochs = model.n_epochs\n",
    "    el_time =  model.elapsed_time\n",
    "\n",
    "    print('\\ntraining:')\n",
    "    print('auc train:',auc_train,'auc val:', auc_test)\n",
    "    print('best epoch:', best_epoch, 'epoch cnt:', n_epochs, \n",
    "          'time:',el_time)\n",
    "\n",
    "    preds = model.predict(X_test)\n",
    "    auc = AucCalc.evaluate(preds, y_test)\n",
    "    significance, thr, sig, bg = SigCalc.evaluate(preds, y_test, weights_test)\n",
    "    \n",
    "    \n",
    "    preds = model.predict(X_val)\n",
    "    significance2, thr2, sig2, bg2 = SigCalc.evaluate(preds, y_val, weights_val)\n",
    "\n",
    "\n",
    "    print('test auc:', auc)\n",
    "    print('test sig:', significance)\n",
    "\n",
    "    return model, significance, auc, significance2, auc_test, sig2\n",
    "\n",
    "\n",
    "\n",
    "for i in range(20):\n",
    "    mld = CSampledDatasetExpEvents(t.table, (20000,100000), (10000,100000), rs=i)\n",
    "    #mld = CSampledDatasetAcc(t.table, (20000,100000), (10000,100000))\n",
    "    mld.printInfo()\n",
    "\n",
    "\n",
    "    X_train = mld.X_train\n",
    "    X_train.drop(columns = ['njets_CBT5','inv3jets'], inplace = True)\n",
    "    y_train = mld.y_train\n",
    "    types_train = mld.types_train\n",
    "    weights_train = mld.weights_train\n",
    "\n",
    "    X_test = mld.X_test\n",
    "    X_test.drop(columns = ['njets_CBT5','inv3jets'], inplace = True)\n",
    "    y_test = mld.y_test\n",
    "    types_test = mld.types_test\n",
    "    weights_test = mld.weights_test\n",
    "\n",
    "\n",
    "    X_val = mld.X_val\n",
    "    X_val.drop(columns = ['njets_CBT5','inv3jets'], inplace = True)\n",
    "    y_val = mld.y_val\n",
    "    types_val = mld.types_val\n",
    "    weights_val = mld.weights_val\n",
    "\n",
    "\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "    dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "    dval = xgb.DMatrix(X_val, label=y_val)\n",
    "    AucCalc = CEvaluationAUC()\n",
    "    SigCalc = CEvaluationSignificance()\n",
    "    \n",
    "    \n",
    "    \n",
    "    if i<10:\n",
    "        r = 0\n",
    "    else:\n",
    "        r = 1\n",
    "            \n",
    "    row = dfa.iloc[r,:]\n",
    "    colsample_bytree = row['colsample_bytree']\n",
    "\n",
    "    print(i,row['colsample_bytree'])\n",
    "\n",
    "    #if row['df_id'] == 5:\n",
    "    #    colsample_bytree = 0.6    \n",
    "        \n",
    "    best_epoch_t = row['best_epoch']\n",
    "\n",
    "    (model, significance, auc, sig_val, auc_val, nsig) = evaluate_model(row['lambda'], row['alpha'], row['gamma'],\n",
    "                   row['min_child_weight'], colsample_bytree)\n",
    "        \n",
    "    \n",
    "    results.append([model, significance, auc, sig_val, auc_val, nsig])\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cern_bachelor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
